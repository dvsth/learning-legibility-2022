{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('dvsth/test_to_delete', use_auth_token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv('wave1_annotations.csv'), pd.read_csv('wave2_annotations.csv'), pd.read_csv('wave3_annotations.csv')], ignore_index=True)\n",
    "\n",
    "# explode the data column into a list of dictionaries\n",
    "df = pd.concat([df.drop('data', axis=1), df['data'].apply(lambda x: eval(x)).apply(pd.Series)], axis=1)\n",
    "\n",
    "# melt each pair of each batch into its own row\n",
    "df = df.melt(['workerId', 'job_id'], list(range(0, 19)))\n",
    "\n",
    "# extract the annotation for each batch\n",
    "df = pd.concat([df.drop('value', axis=1), df['value'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# extract the original word from the annotation\n",
    "df['original'] = df['0'].apply(lambda x: x['original'])\n",
    "\n",
    "# count how many annotations there are for each original word, store it in the 'count' column\n",
    "df['count'] = df.groupby('original')['choice'].transform('count')\n",
    "\n",
    "to_send = df[['0', '1', 'choice']].copy()\n",
    "to_send['k'] = to_send['0'].apply(lambda x: x['k'])\n",
    "to_send['k1'] = to_send['1'].apply(lambda x: x['k'])\n",
    "to_send['n'] = to_send['0'].apply(lambda x: x['n'])\n",
    "to_send['n1'] = to_send['1'].apply(lambda x: x['n'])\n",
    "to_send['word'] = to_send['0'].apply(lambda x: x['original'])\n",
    "to_send['word0'] = to_send['0'].apply(lambda x: x['corrupted'])\n",
    "to_send['word1'] = to_send['1'].apply(lambda x: x['corrupted'])\n",
    "to_send['model0'] = to_send['0'].apply(lambda x: x['model'])\n",
    "to_send['model1'] = to_send['1'].apply(lambda x: x['model'])\n",
    "to_send.drop(['0', '1'], axis=1, inplace=True)\n",
    "to_send['as_str'] = to_send.apply(lambda x: str([x['word0'], x['word1'], x['word']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>k</th>\n",
       "      <th>k1</th>\n",
       "      <th>n</th>\n",
       "      <th>n1</th>\n",
       "      <th>word</th>\n",
       "      <th>word0</th>\n",
       "      <th>word1</th>\n",
       "      <th>model0</th>\n",
       "      <th>model1</th>\n",
       "      <th>as_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.643711</td>\n",
       "      <td>0.699099</td>\n",
       "      <td>distributed</td>\n",
       "      <td>ԁisʈriþuʈeԁ</td>\n",
       "      <td>dᒨstṙᒨḃuߙɛⅾ</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>trocr_2fff</td>\n",
       "      <td>['ԁisʈriþuʈeԁ', 'dᒨstṙᒨḃuߙɛⅾ', 'distributed']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>0.534371</td>\n",
       "      <td>0.245311</td>\n",
       "      <td>specified</td>\n",
       "      <td>sᴅeດiƚieή</td>\n",
       "      <td>spёcifie⍺</td>\n",
       "      <td>trocr_2fff</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>['sᴅeດiƚieή', 'spёcifie⍺', 'specified']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>0.627468</td>\n",
       "      <td>0.725031</td>\n",
       "      <td>exec</td>\n",
       "      <td>e⨲e⊂</td>\n",
       "      <td>⋸x⋸c</td>\n",
       "      <td>trocr_2fff</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>['e⨲e⊂', '⋸x⋸c', 'exec']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0.630070</td>\n",
       "      <td>0.566629</td>\n",
       "      <td>possess</td>\n",
       "      <td>໐oͽͽẽss</td>\n",
       "      <td>poકsȇકs</td>\n",
       "      <td>imgdot_2fff</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>['໐oͽͽẽss', 'poકsȇકs', 'possess']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>0.414475</td>\n",
       "      <td>0.236869</td>\n",
       "      <td>suits</td>\n",
       "      <td>ឧվits</td>\n",
       "      <td>suitе</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>imgdot_2fff</td>\n",
       "      <td>['ឧվits', 'suitе', 'suits']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21674</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>0.325773</td>\n",
       "      <td>0.269436</td>\n",
       "      <td>career</td>\n",
       "      <td>cӑreer</td>\n",
       "      <td>careᏼr</td>\n",
       "      <td>imgdot_2fff</td>\n",
       "      <td>imgdot_2fff</td>\n",
       "      <td>['cӑreer', 'careᏼr', 'career']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21675</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>0.175927</td>\n",
       "      <td>0.235391</td>\n",
       "      <td>colorado</td>\n",
       "      <td>Ƈolorado</td>\n",
       "      <td>coloⲙado</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>trocr_2fff</td>\n",
       "      <td>['Ƈolorado', 'coloⲙado', 'colorado']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21676</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>76</td>\n",
       "      <td>0.192853</td>\n",
       "      <td>0.254207</td>\n",
       "      <td>brief</td>\n",
       "      <td>brief</td>\n",
       "      <td>brie⦍</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>imgdot_2fff</td>\n",
       "      <td>['brief', 'brie⦍', 'brief']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21677</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.038917</td>\n",
       "      <td>0.056914</td>\n",
       "      <td>barbados</td>\n",
       "      <td>barbados</td>\n",
       "      <td>barbados</td>\n",
       "      <td>trocr_2fff</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>['barbados', 'barbados', 'barbados']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21678</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>0.406554</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>mi♋ᥴelιàמөous</td>\n",
       "      <td>miⳉceⅠlȃຖeoUs</td>\n",
       "      <td>trocr_2fff</td>\n",
       "      <td>clip1_2fff</td>\n",
       "      <td>['mi♋ᥴelιàמөous', 'miⳉceⅠlȃຖeoUs', 'miscellane...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21679 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       choice   k  k1         n        n1           word          word0  \\\n",
       "0           0   1   8  0.643711  0.699099    distributed    ԁisʈriþuʈeԁ   \n",
       "1           3  47  46  0.534371  0.245311      specified      sᴅeດiƚieή   \n",
       "2           2  13  23  0.627468  0.725031           exec           e⨲e⊂   \n",
       "3           3  30  40  0.630070  0.566629        possess        ໐oͽͽẽss   \n",
       "4           1  35  47  0.414475  0.236869          suits          ឧվits   \n",
       "...       ...  ..  ..       ...       ...            ...            ...   \n",
       "21674       1  25  26  0.325773  0.269436         career         cӑreer   \n",
       "21675       0  13  23  0.175927  0.235391       colorado       Ƈolorado   \n",
       "21676       0  62  76  0.192853  0.254207          brief          brief   \n",
       "21677       2   5  16  0.038917  0.056914       barbados       barbados   \n",
       "21678       1  23  17  0.472097  0.406554  miscellaneous  mi♋ᥴelιàמөous   \n",
       "\n",
       "               word1       model0       model1  \\\n",
       "0        dᒨstṙᒨḃuߙɛⅾ   clip1_2fff   trocr_2fff   \n",
       "1          spёcifie⍺   trocr_2fff   clip1_2fff   \n",
       "2               ⋸x⋸c   trocr_2fff   clip1_2fff   \n",
       "3            poકsȇકs  imgdot_2fff   clip1_2fff   \n",
       "4              suitе   clip1_2fff  imgdot_2fff   \n",
       "...              ...          ...          ...   \n",
       "21674         careᏼr  imgdot_2fff  imgdot_2fff   \n",
       "21675       coloⲙado   clip1_2fff   trocr_2fff   \n",
       "21676          brie⦍   clip1_2fff  imgdot_2fff   \n",
       "21677       barbados   trocr_2fff   clip1_2fff   \n",
       "21678  miⳉceⅠlȃຖeoUs   trocr_2fff   clip1_2fff   \n",
       "\n",
       "                                               as_string  \n",
       "0          ['ԁisʈriþuʈeԁ', 'dᒨstṙᒨḃuߙɛⅾ', 'distributed']  \n",
       "1                ['sᴅeດiƚieή', 'spёcifie⍺', 'specified']  \n",
       "2                               ['e⨲e⊂', '⋸x⋸c', 'exec']  \n",
       "3                      ['໐oͽͽẽss', 'poકsȇકs', 'possess']  \n",
       "4                            ['ឧվits', 'suitе', 'suits']  \n",
       "...                                                  ...  \n",
       "21674                     ['cӑreer', 'careᏼr', 'career']  \n",
       "21675               ['Ƈolorado', 'coloⲙado', 'colorado']  \n",
       "21676                        ['brief', 'brie⦍', 'brief']  \n",
       "21677               ['barbados', 'barbados', 'barbados']  \n",
       "21678  ['mi♋ᥴelιàמөous', 'miⳉceⅠlȃຖeoUs', 'miscellane...  \n",
       "\n",
       "[21679 rows x 11 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('full_test_set_with_nk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_valid = data['valid']['words']\n",
    "list_train = data['train']['words']\n",
    "list_test = data['test']['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_send['set'] = to_send['as_str'].apply(lambda x: 'valid' if x in list_valid else 'train' if x in list_train else 'test' if x in list_test else 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_send.drop_duplicates(subset=['as_str'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train      14283\n",
       "test        3588\n",
       "valid       3237\n",
       "unknown      299\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_send['set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = to_send[to_send['set'] == 'train'].drop(['as_str', 'set'], axis=1)\n",
    "valid = to_send[to_send['set'] == 'valid'].drop(['as_str', 'set'], axis=1)\n",
    "test = df1.drop(['as_str'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.concat([to_send, df1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'train': train, 'valid': valid, 'test': test}\n",
    "d = {k: Dataset.from_pandas(v, preserve_index=False) for k, v in d.items()}\n",
    "d = DatasetDict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['choice', 'k', 'k1', 'n', 'n1', 'word', 'word0', 'word1', 'model0', 'model1'],\n",
       "        num_rows: 14283\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['choice', 'k', 'k1', 'n', 'n1', 'word', 'word0', 'word1', 'model0', 'model1'],\n",
       "        num_rows: 3237\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['choice', 'k', 'k1', 'n', 'n1', 'word', 'word0', 'word1', 'model0', 'model1'],\n",
       "        num_rows: 3712\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n",
      "Parameter 'indices'=range(0, 14283) of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c174f87694441b8d93aeb12a715286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split valid to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3991b1769e0d462d8f174a5bde2b7697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split test to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5d1129b89e45479f814430bdf3bf0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.push_to_hub('LEGIT-2023', private=False, token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9a33fd02dcd74fd53701f10c0433ded41be0a0f53c9699722a73f690e69c2bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
